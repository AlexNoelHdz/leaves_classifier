{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "# Images\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import geffnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(41)\n",
    "#Data Tranforms (Augmentation and Normalization)\n",
    "train_transforms = transforms.Compose([\n",
    "                                       # Rotación aleatoria de la imagen entre -30 y +30 grados para mejor entrenamiento\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       # Aplica una perspectiva aleatoria con una distorsión máxima del 40%\n",
    "                                       transforms.RandomPerspective(distortion_scale=0.4),\n",
    "                                       # Voltea la imagen horizontalmente con una probabilidad del 60%\n",
    "                                       transforms.RandomHorizontalFlip(0.6),\n",
    "                                       # Cambia el tamaño de la imagen a 224x224 píxeles\n",
    "                                       transforms.Resize(size=(224,224)),\n",
    "                                       # Cambia el tamaño de la imagen a 224x224 píxeles\n",
    "                                       transforms.ToTensor(),\n",
    "                                       # Normaliza cada canal de la imagen.\n",
    "                                       # Los valores son estándares de ImageNet.\n",
    "                                       # Resta la media y divide por la desviación estándar, canal por canal.\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])])\n",
    "valid_transforms = transforms.Compose([\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.RandomHorizontalFlip(0.6),\n",
    "                                       transforms.Resize(size=(224,224)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])])\n",
    "test_transforms = transforms.Compose([transforms.Resize(size=(224,224)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir = ''\n",
    "#Getting all the data with PyTorch Datasets\n",
    "train_data = datasets.ImageFolder(data_dir + r'/train', transform= train_transforms)\n",
    "val_data = datasets.ImageFolder(data_dir + r'/val', transform= valid_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + r'/test', transform= test_transforms)\n",
    "\n",
    "#Loading the data into PyTorch DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size= 64, shuffle = True,num_workers=4)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size= 64, shuffle = True,num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size= 64, shuffle = True,num_workers=4)\n",
    "\n",
    "#Creating a dictionary of all classes\n",
    "classes = dict(zip(list(range(len(train_data.classes))),train_data.classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
